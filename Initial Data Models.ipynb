{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 30000 \n",
      "Number of columns: 24\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe and reset our header\n",
    "df = pd.read_csv('Dataset for Models.csv')\n",
    "\n",
    "# Check dimesions of data \n",
    "print('Number of rows:', df.shape[0], '\\n'\n",
    "      'Number of columns:', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 23)\n",
      "(30000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: DEFAULT_STATUS, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Matrix\n",
    "features = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE_BIN', 'PAY_1','PAY_2', 'PAY_3', \n",
    "            'PAY_4', 'PAY_5', 'PAY_6','BILL_AMT1', 'BILL_AMT2',\n",
    "            'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "            'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "y = df.DEFAULT_STATUS\n",
    "\n",
    "X = df[features]\n",
    "#y = df[target]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 2nd dataframe for manipulation\n",
    "data=pd.read_csv('Dataset for Models.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import decision treet for visual\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(data,X)\n",
    "#tree.export_graphviz(clf, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graphvis to visualize decision tree\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#represetation of the data inputted.\n",
    "#name of each features\n",
    "#identifying name of the target classes\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "...                      feature_names= feature_names,  \n",
    "...                      class_names=data.DEFAULT_STATUS\n",
    "...                      filled=True, rounded=True,  \n",
    "...                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "#show visual tree\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf,\n",
    "...     out_file='tree.dot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(20,20))\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Kendall Correlation\n",
    "plt.figure(figsize=(20,20))\n",
    "kcor = df.corr(method='kendall')\n",
    "sns.heatmap(kcor, annot=True, cmap=plt.cm.Reds)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of DEFAULT_STATUS is lowest at -0.15 with LIMIT_BAL. \n",
    "This negative correlation indicates that higher the credit limit, lower the chance of defaulting.\n",
    "\n",
    "Highest is 0.4 correlate with PAY_1.\n",
    "This positive correlation indicates that longer the period of delayed Payment, higher chances of Default.\n",
    "\n",
    "All PAY_n variables from PAY_1.....PAY_6 have higher correlation to DEFAULT_STATUS compare to other variables.\n",
    "Hence, clients payment behaviour strongly indication their chances of Defaulting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle the target imbalance import SMOTE from imblearn.over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2019)\n",
    "X_resample, y_resample = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model \n",
    "logreg = LogisticRegression(solver='liblinear', random_state=2019)\n",
    "# fit the model with data\n",
    "logreg.fit(X_resample,y_resample)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('The accuracy of the Logistic Regression using all variables is:',metrics.accuracy_score(y_test, y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=10, random_state=2019) \n",
    "\n",
    "# training the classifier\n",
    "classifier.fit(X_resample, y_resample) \n",
    "\n",
    "# do our predictions on the test\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('The accuracy of the Decision Tree using all variables is:',metrics.accuracy_score(y_test, y_pred).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNeighborsClassifier from sklearn.neighbors \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "# training the classifier\n",
    "knn.fit(X_resample,y_resample)\n",
    "# do our predictions on the test\n",
    "y_pred = knn.predict(X_test)\n",
    "print('The accuracy of the KNN using all variables is:',metrics.accuracy_score(y_test, y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ther necessary dependencies\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Feature extraction\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "# calculate the score for the selected features\n",
    "score_stand = rfe.score(X,y)\n",
    "print(\"Model Score with selected features is: %f (%f)\" % (score_stand.mean(), score_stand.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(X.columns)\n",
    "print('Most important features (RFE): %s'% feature_names[rfe.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(3).plot(kind='barh')\n",
    "plt.title('Top 3 most important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Features based on Correlation \n",
    "X1 = df[['PAY_1','LIMIT_BAL','BILL_AMT1']]\n",
    "y1 = df.DEFAULT_STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle the target imbalance import SMOTE from imblearn.over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2019)\n",
    "X_resample, y_resample = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=2019)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_resample,y_resample)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy with Logistic Regression:\", metrics.accuracy_score(y_test, y_pred).round(2))\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNeighborsClassifier from sklearn.neighbors \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "# training the classifier\n",
    "knn.fit(X_resample,y_resample)\n",
    "\n",
    "# do our predictions on the test\n",
    "y_pred = knn.predict(X_test)\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "#confusion_matrix_y1 = confusion_matrix(y4_test, y4_pred)\n",
    "#print('Accuracy of classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))\n",
    "print(\"Accuracy with kNN:\", metrics.accuracy_score(y_test, y_pred).round(2))\n",
    "print('Confusion Matrix for k-NN Classfier:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Classification Report for k-NN Classfier:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=10, random_state=2019) \n",
    "\n",
    "# training the classifier\n",
    "classifier.fit(X_resample, y_resample)\n",
    "# do our predictions on the test\n",
    "y_pred = classifier.predict(X_test)\n",
    "# see how good we did on the test\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred).round(3))\n",
    "print('Classification Report for DecisionTree Classfier:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
