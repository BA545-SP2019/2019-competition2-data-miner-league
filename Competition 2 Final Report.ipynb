{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Miner League Competition 2 Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question\n",
    "\n",
    "- Our client is seeking advanced and novel methods to prepare the collected data, to prepare for the classification purpose. Our goal is to to design, implement, and deploy a classification analysis to predict whether a credit card customer will default the payment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicable Packags\n",
    " - Before reading in the csv file for competition 2 there were several packages to be loaded into the notebook for use. These packages enabled us to use visualization methods as well as feature optimization methods.\n",
    "     - Imported packages consisited of NUMPY, PANDAS, MATLPOTLIB, SEABORN and SKLEARN\n",
    "     - Sub packages used for data models include model_selection, croos_val_score, train_test_split, metrics, confusion_matrix, classification_report, roc_auc_score and accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "- During the initial data exploration process we used the data dictionary to determine the data types of the stored variables and whether or not these values were continuous or binary.\n",
    "    - We identified that the data set contained 24 attributes and 30000 rows. The initial dataset contained no missing data and determined descritive statistics for each variable.\n",
    "- Correlation\n",
    "    - Using Seaborn we determined the relationships between the explanatory and target variables (Will the client default on the payment)\n",
    "        - Variables PAY_1 - PAY_6 had the highes correlation to the Default status and PAY_AMT1 - PAY_AMT6 had the lowest correlation score to the Default status variable. Correlation of Default status is lowest at -.15 with LIMIT_BAL. This negative correlation indicates that the higher the credit limit, lower the chance of default. Correlation of Default Status is highestat .4 with PAY_1. THis positive correlation indicates that the longer the period of delayed Payment, higher chances of defatult occured. The clients payment behavior is a strong indication of their chances of defaulting.\n",
    "    - The correlation analysis was a first step in determing which explanatory variables were the biggest default status drivers.\n",
    "- Target imbalance\n",
    "    - To handle target imbalcance within the variable we imported SMOTE from imblearn.oversampling and resampled the the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Analysis\n",
    "- After resampling the data we imported the logisitc regression package from sklearn, partitioned the data into a test/train split and found the accuracy of this model to be around 69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "- After importing the DecisionTreeClassifier module we ran the classifier using all the variables included in the data set and recieved an accuracy score of 1.0\n",
    "\n",
    "### K-NN Classifier\n",
    "- After importing the KNeighborsClassifier module we ran the classifier using all of the variables included in the data set and recieved an accuracy socre of .64.\n",
    "\n",
    "- These accuracy scores obtained from running these classifiers using all of the variables can be revised to use only the variables that are highly correlated with the user default status. Feature selection can be used to narrow down the explanatory variables to create the most accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection USing RFE\n",
    "- using the Feauture selection module within the sklearn package we re ran the logisitc regression using the variables that were deemed to be the most efficient. The feature selection ranked the variables in order of the standard score. The three most important features were Pay_AMT1, PAY_AMT2 and PAY_AMT4. The model score using these features yielded an accuracy of 77.8%\n",
    "\n",
    "### Feature Importance\n",
    "- wanted to cross check the top three variables found about so we created a feature importance model and the three most important explanatory variables according this method were PAY_2, PAY_1 and DEFAULT_Status which is the target variable.\n",
    "- We re initialized the logistic regression model and used PAY_1, Limit_BAL and Bill_AMT1 asour new explanatory variables and this yielded a new accuracy of 75%\n",
    "- We also re ran our K Neighbors classification model and recieved an accuracy score of 63% which is lower than the initial k Neighbors classifier model.\n",
    "- Using ne new features also re ran the Decision Tree Classifier and yielded an accuracy score of 71.3%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
